<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Joni Vaatainen - My Projects</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Introduction</a></li>
							<li class="active"><a href="projects.html">My Projects</a></li>
							<li><a href="skillset.html">Skillset</a></li>
							<li><a href="history.html">Experience</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/joni-v%C3%A4%C3%A4t%C3%A4inen-075408147/" class="icon brands fa-linkedin"><span class="label">linkedin</span></a></li>
							<li><a href="https://github.com/jonivaatainen" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<section class="post">
							<header class="major">
								<h1>Current Projects</h1>

						<!-- Post -->
						<section class="post">
							<h3>Modality invariant representation for efficient task learning (Master’s thesis research)</h3>
							<p>The aim of the research is to discover an unsupervised representation learning method for multimodal data (e.g. visual, depth, tactile, proprioception, etc.) that is scalable and can be used in different domains. The advantages of the researched method would be that (1) the trained model can produce higher quality embeddings when trained with multiple modalities w.r.t. to just training with one modality and (2) has intrinsic robustness against missing modalities after training phase thanks to its architecture.</p>
							<p>The researched method could be used for example in robot control tasks (e.g. stacking objects, in-hand manipulation, etc.) by using Inverse Reinforcement Learning or in object/pose/task classification.</p>
							<p>Videos:</p>
							<div class="row">
								<div class="col-6 col-12-small">
									<ul class="actions small">
										<li><a href="videos/results_weight.mp4" class="button small">weight classification</a></li>
								</div>
								<div class="col-6 col-12-small">
									<ul class="actions small">
										<li><a href="videos/results_state_retrieval.mp4" class="button small">cross-modal state retrieval</a></li>
								</div>
							</div>
						</section>

						<!-- Seperator -->
						<hr />

						<section class="post">
							<header class="major">
								<h1>Past Projects</h1>
						<!-- Post -->
						<section class="post">
							<h3>Visual Task Progress Estimation with Appearance Invariant Embeddings for Robot Control and Planning</h3>
							<p>This work was achieved when I was at Preferred Networks as Research Intern in 2019. We developed a representation method for task progress estimation. The method uses the consistency of the progress among different examples and viewpoints of a task to train a deep neural network to map images into measurable features.
							<div class="row">
								<div class="col-6 col-12-small">
									<ul class="actions small">
										<li><a href="https://arxiv.org/pdf/2003.06977.pdf" class="button small">pre-print</a></li>
								</div>
								<div class="col-6 col-12-small">
									<ul class="actions small">
										<li><a href="https://gjmaeda.github.io/research/invariant_task_progress_estimation/task_progress_estimation_1min.mp4" class="button small">video</a></li>
								</div>
							</div>
						</section>


						<!-- Post -->
						<section class="post">
							<h3>ABB Marine - Remote Control System (RCS)</h3>
							<p>I was one of the main developers of the ABB marine’s Remote Control Systems (RCS) in the R&D department. The update introduced new bridge devices using CANopen and UDP communication protocols and new bridge control logic for three ABB Azipod (propulsion unit) control systems. The programming languages I used were mainly CODESYS for ABB’s AC500 Programming Logic Controller (PLC) and C# based language for ABB’s AC800M PLC and ABB’s Panel Builder HMI application. Besides the control logic for the bridge’s propulsion control, I also created the communication interfaces for integrating the new devices to the existing control system.</p>
							<ul class="actions small">
								<li><a href="https://new.abb.com/docs/librariesprovider91/leaflets-brochures/imi_leaflet_rev5.pdf?status=Temp&sfvrsn=0.3105079126544297" class="button small">Intro to RCS</a></li>
						</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
					</footer>
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>